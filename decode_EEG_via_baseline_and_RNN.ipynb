{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decode EEG via baseline and RNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmningmei/mask_image_FOREST/blob/master/decode_EEG_via_baseline_and_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYVM2jnoU62d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A1I5LUGYOtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8lHm5xdV8G0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(file_id,file_name):\n",
        "    downloaded = drive.CreateFile({'id':file_id})\n",
        "    downloaded.GetContentFile(f'{file_name}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKrPsxVDVM1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eeg_id = 'https://drive.google.com/open?id=1pIjvShObTC6VGkWKKdPS9kjtmUq05U7t'.split('id=')[-1]\n",
        "get_data(eeg_id,'epochs.fif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKw5t_NRWIGM",
        "colab_type": "text"
      },
      "source": [
        "# experiment\n",
        "\n",
        "## targets: living v.s. nonliving objects -- images\n",
        "\n",
        "## conscious state: unconscious, glimpse, conscious\n",
        "\n",
        "# preprocessing steps\n",
        "\n",
        "## highpass filter at 0.0001 Hz\n",
        "\n",
        "## linear detrend"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRL8ZAq_Wh2q",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model: Logistic Regression (C = 1, L2 panelty), cv = StratifiedShuffleSplit(n_splits = 300, test_size = 0.2)\n",
        "\n",
        "## Decode living v.s. nonliving using the whole epoch as feature (n_sample x n_channels x n_timepoints)\n",
        "\n",
        "## Decode living v.s. nonliving at each time point (n_sample x n_channels at each timepoint)\n",
        "\n",
        "## Decode living v.s. nonliving at each time point and generalize to other time points - temporal generalization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fwa5FJ0XaxF",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Model Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1uQebs6YoQl",
        "colab_type": "text"
      },
      "source": [
        "## Unconscious"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8Zs4J3CYrk_",
        "colab_type": "text"
      },
      "source": [
        "### Temporal Decoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuRoQ4KDXnwi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "51396e5c-24af-4286-ebb6-3974c7a21e1e"
      },
      "source": [
        "Image(url = 'https://raw.githubusercontent.com/nmningmei/mask_image_FOREST/master/figures/EEG/decode/mattin_7_12_2019/temporal%20decoding%20(unconscious).png',\n",
        "     height = 500)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/nmningmei/mask_image_FOREST/master/figures/EEG/decode/mattin_7_12_2019/temporal%20decoding%20(unconscious).png\" height=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LSFZbm5YtW6",
        "colab_type": "text"
      },
      "source": [
        "### Temporal Generalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y51_ig1wYUmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "37f902c0-73c5-4d18-f3b6-b3d71e2716ab"
      },
      "source": [
        "Image(url = 'https://raw.githubusercontent.com/nmningmei/mask_image_FOREST/master/figures/EEG/decode/mattin_7_12_2019/temporal%20generalization%20(unconscious).png',\n",
        "     height = 500)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/nmningmei/mask_image_FOREST/master/figures/EEG/decode/mattin_7_12_2019/temporal%20generalization%20(unconscious).png\" height=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2TClwLoY2GF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "bdfeb8dc-9da6-4ba2-b39b-68f330ba32f2"
      },
      "source": [
        "Image(url = 'https://raw.githubusercontent.com/nmningmei/mask_image_FOREST/master/figures/EEG/decode/mattin_7_12_2019/stats%20(p%20values%2C%20unconscious).png',\n",
        "     height = 500)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://raw.githubusercontent.com/nmningmei/mask_image_FOREST/master/figures/EEG/decode/mattin_7_12_2019/stats%20(p%20values%2C%20unconscious).png\" height=\"500\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6dQWfrpZANh",
        "colab_type": "text"
      },
      "source": [
        "# RNN - 1 layer, 1 unit\n",
        "\n",
        "## Rationale to use RNN instead of the baseline model: complexity and temporal dynamics\n",
        "\n",
        "### complexity of the model:\n",
        "When fitting the baseline model to the data, each instance is 60 channels x 150 time points, after downsampling from 1000 Hz to 100 Hz. This means we will have to fit 60 x 150 = 9000 parameters to find the boundary that discriminate living v.s. nonliving categories. When we perform temporal decoding and/or temporal generalization, it is essentially the same thing, except the parameters to fit are divided into 150 parts, and for each part, we will fit 60 parameters. \n",
        "\n",
        "For a 1 layer and 1 unit RNN, you will see it has around 500 parameters (16 times smaller) to fit when the input dimension is 60 x 150. That is because we consider the channels to be the \"embedding features\" and the embedding was performed along the 150 time steps. We re-formulate the EEG decoding problem to a natural language processing modelling problem. \n",
        "\n",
        "### temporal dynamics\n",
        "As we know, RNN is good for temporal dynamics modelling, being better than logistic regressions. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLZK5a55aZYv",
        "colab_type": "text"
      },
      "source": [
        "## lots of helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XecXc7sNa7xx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c4d43b5b-1cd2-4b34-a03a-df6a98f3f10d"
      },
      "source": [
        "!pip install mne"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.6/dist-packages (0.18.2)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from mne) (1.16.4)\n",
            "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from mne) (1.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkBBEbtDajAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mne\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers,Model, optimizers,losses,regularizers,callbacks#,Sequential\n",
        "from tensorflow.keras import metrics as k_metrics\n",
        "import tensorflow.keras.backend as K\n",
        "from collections import Counter\n",
        "from sklearn import metrics\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbwIQgNPY9a1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_CallBackList(model_name,monitor='val_loss',mode='min',verbose=0,min_delta=1e-4,patience=50,frequency = 1):\n",
        "    from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\n",
        "    \"\"\"\n",
        "    Make call back function lists for the keras models\n",
        "    \n",
        "    Inputs\n",
        "    -------------------------\n",
        "    model_name: directory of where we want to save the model and its name\n",
        "    monitor: the criterion we used for saving or stopping the model\n",
        "    mode: min --> lower the better, max --> higher the better\n",
        "    verboser: printout the monitoring messages\n",
        "    min_delta: minimum change for early stopping\n",
        "    patience: temporal windows of the minimum change monitoring\n",
        "    frequency: temporal window steps of the minimum change monitoring\n",
        "    \n",
        "    Return\n",
        "    --------------------------\n",
        "    CheckPoint: saving the best model\n",
        "    EarlyStopping: early stoppi....\n",
        "    \"\"\"\n",
        "    checkPoint = ModelCheckpoint(model_name,# saving path\n",
        "                                 monitor          = monitor,# saving criterion\n",
        "                                 save_best_only   = True,# save only the best model\n",
        "                                 mode             = mode,# saving criterion\n",
        "                                 save_freq        = frequency,# frequency of check the update \n",
        "                                 verbose          = verbose# print out (>1) or not (0)\n",
        "                                 )\n",
        "    earlyStop = EarlyStopping(   monitor          = monitor,\n",
        "                                 min_delta        = min_delta,\n",
        "                                 patience         = patience,\n",
        "                                 verbose          = verbose, \n",
        "                                 mode             = mode,\n",
        "                                 )\n",
        "    return [checkPoint,earlyStop]\n",
        "def preprocess_features(X,vectorizer = None,scaler = None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer          = mne.decoding.Vectorizer()\n",
        "        X_vec               = vectorizer.fit_transform(X)\n",
        "    else:\n",
        "        X_vec               = vectorizer.transform(X)\n",
        "    if scaler is None:\n",
        "        scaler              = StandardScaler()\n",
        "        X_vec_standard      = scaler.fit_transform(X_vec)\n",
        "    else:\n",
        "        X_vec_standard      = scaler.transform(X_vec)\n",
        "    X_vec_tran          = vectorizer.inverse_transform(X_vec_standard)\n",
        "    \n",
        "    return X_vec_tran,vectorizer,scaler\n",
        "def prepare_data_batch(X,y,batch_size = 32):\n",
        "    \"\"\"\n",
        "    prepare the data for training, validating, and testing\n",
        "    make sure the data in a certain range and fit to the batch size\n",
        "    \n",
        "    Inputs \n",
        "    -------------------------------\n",
        "    X: input features, (n_sample x n_channels x n_timesteps)\n",
        "    y: input labels, (n_samples x n_categories)\n",
        "    batch_size: int, batch size\n",
        "    Return\n",
        "    -------------------------------\n",
        "    processed X,y\n",
        "    \"\"\"\n",
        "    X       = X / np.abs(X.max())\n",
        "    remain_ = X.shape[0] % batch_size\n",
        "    if remain_ != 0:\n",
        "        np.random.seed(12345)\n",
        "        idx_    = np.random.choice(X.shape[0],size = X.shape[0] - remain_)\n",
        "        X,y     = X[idx_],y[idx_]\n",
        "        \n",
        "    return X,y\n",
        "def call_back_dict(classifier,care = 'loss'):\n",
        "    if care == 'loss':\n",
        "        return dict(\n",
        "                monitor     = 'val_{}'.format(classifier.metrics_names[0]),\n",
        "                mode        = 'min',\n",
        "                patience    = 3,\n",
        "                min_delta   = 1e-3)\n",
        "    elif care == 'metric':\n",
        "        return dict(\n",
        "                monitor     = 'val_{}'.format(classifier.metrics_names[-1]),\n",
        "                mode        = 'max',\n",
        "                patience    = 4,\n",
        "                min_delta   = 1e-4)\n",
        "    else:\n",
        "        print('why?')\n",
        "\n",
        "def build_model(timesteps,\n",
        "                data_dim,\n",
        "                n_units     = 1,\n",
        "                batch_size  = 32,\n",
        "                n_layers    = 1,\n",
        "                drop        = True,\n",
        "                l1          = 1e-2,\n",
        "                l2          = 1e-2,):\n",
        "    \"\"\"\n",
        "    initialize a RNN model\n",
        "    \n",
        "    Inputs\n",
        "    -----------------------------------------------\n",
        "    timesteps: int, length of time steps\n",
        "    data_dim: int, number of features, such as n_channels\n",
        "    n_units: int, number of RNN units, each unit has the same number of cells as the number of time steps\n",
        "    batch_size: int, batch size\n",
        "    n_layers: int, number of RNN layers, this is independent from the number of units\n",
        "    drop: bool, extra dropout layer\n",
        "    l1: float, L1 penalty, higher is more sparse\n",
        "    l2: float, L2 penalty, higher is lower the magnitude of the weights\n",
        "    \"\"\"\n",
        "    K.clear_session()\n",
        "    inputs          = layers.Input(\n",
        "                                   shape        = (timesteps,data_dim,),\n",
        "                                   batch_size   = batch_size,# keras way (batch_size,timesteps,data_dim),\n",
        "                                   name         = 'inputs')\n",
        "    # if we want to make multiple layers, I am not going to use the \"inputs\" tensor because this has to be the \"Input\" object without any chance\n",
        "    # this will make a copy of it\n",
        "    inputs_         = inputs\n",
        "    # first RNN layer\n",
        "    RNN,state_h = layers.GRU(units              = n_units,\n",
        "                             return_state       = True,\n",
        "                             return_sequences   = True,\n",
        "                             kernel_regularizer = regularizers.l2(l2),\n",
        "                             name               = 'rnn{}'.format(1))(inputs_)\n",
        "    RNN         = layers.BatchNormalization(\n",
        "                             name               = 'norm{}'.format(1))(RNN)\n",
        "    if n_layer < 2: # don't need to do this if it is not the only RNN layer\n",
        "        if n_units == 1:\n",
        "            # if we define only 1 RNN unit, the last dimension of the output would be 1\n",
        "            # thus, if this is the only layer, we could squeeze the 1 out\n",
        "            RNN         = layers.Lambda(lambda x: K.squeeze(x, 2))(RNN)\n",
        "        else:\n",
        "            # otherwise, we will have the RNN outputs from multiple units\n",
        "            # then, we could find the averages over these units\n",
        "            # make sure you will average over the last dimension\n",
        "            RNN         = layers.GlobalAveragePooling1D(data_format = 'channels_first',\n",
        "                                                        name = 'pool_units{}'.format(1))(RNN)\n",
        "    for n_temp in range(n_layers - 1):\n",
        "        l1 /= 10\n",
        "        l2 /= 10\n",
        "        RNN,state_h = layers.GRU(units              = n_units,\n",
        "                                 return_state       = True,\n",
        "                                 return_sequences   = True,\n",
        "                                 dropout            = 0.1,\n",
        "                                 recurrent_dropout  = 0.25,\n",
        "                                 kernel_regularizer = regularizers.l2(l2),\n",
        "                                 name               = 'rnn{}'.format(n_temp + 2))(RNN,initial_state = [state_h])\n",
        "        RNN         = layers.BatchNormalization(\n",
        "                                 name               = 'norm{}'.format(n_temp + 2))(RNN)\n",
        "        if n_temp == n_layers - 1: # perform dimension check for last RNN layer\n",
        "            if n_units == 1:\n",
        "                RNN         = layers.Lambda(lambda x: K.squeeze(x, 2))(RNN)\n",
        "            else:\n",
        "                RNN         = layers.GlobalAveragePooling1D(data_format = 'channels_first',\n",
        "                                                            name = 'pool_units{}'.format(n_temp + 2))(RNN)\n",
        "        if drop:\n",
        "            RNN         = layers.Dropout(0.25,\n",
        "                                         name           = 'drop{}'.format(n_temp + 2))(RNN)\n",
        "    # connect the RNN with a dense layer - the most parameter consuming layer\n",
        "    outputs             = layers.Dense(2,\n",
        "                                       activation           = 'softmax',\n",
        "                                       activity_regularizer = regularizers.l1(1e-6),\n",
        "                                       name                 = 'outputs',)(RNN)\n",
        "    classifier = Model(inputs,outputs,name = 'clf')\n",
        "    return classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_avg1frZbPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "f771a90e-9280-435a-c5cf-050196021ddc"
      },
      "source": [
        "epochs  = mne.read_epochs('epochs.fif')\n",
        "# resample at 100 Hz to fasten the decoding process\n",
        "print('resampling')\n",
        "epochs.resample(100)\n",
        "\n",
        "conscious   = mne.concatenate_epochs([epochs[name] for name in epochs.event_id.keys() if (' conscious' in name)])\n",
        "see_maybe   = mne.concatenate_epochs([epochs[name] for name in epochs.event_id.keys() if ('glimpse' in name)])\n",
        "unconscious = mne.concatenate_epochs([epochs[name] for name in epochs.event_id.keys() if ('unconscious' in name)])\n",
        "del epochs"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading epochs.fif ...\n",
            "    Read a total of 1 projection items:\n",
            "        Average EEG reference (1 x 60) active\n",
            "    Found the data of interest:\n",
            "        t =    -500.00 ...    1000.00 ms\n",
            "        0 CTF compensation matrices available\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<ipython-input-15-4aee22227091>:1: RuntimeWarning: This filename (epochs.fif) does not conform to MNE naming conventions. All epochs files should end with -epo.fif, -epo.fif.gz, _epo.fif or _epo.fif.gz\n",
            "  epochs  = mne.read_epochs('epochs.fif')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1728 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Not setting metadata\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "1 projection items activated\n",
            "resampling\n",
            "235 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Not setting metadata\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "0 bad epochs dropped\n",
            "975 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Not setting metadata\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "0 bad epochs dropped\n",
            "518 matching events found\n",
            "Applying baseline correction (mode: mean)\n",
            "Not setting metadata\n",
            "Created an SSP operator (subspace dimension = 1)\n",
            "0 bad epochs dropped\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCVFDMkZb3qj",
        "colab_type": "text"
      },
      "source": [
        "## ??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaIzwiXwa4JH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_splits            = 25\n",
        "n_epochs            = int(2e2)\n",
        "print_model         = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XvQP1aNb7tL",
        "colab_type": "text"
      },
      "source": [
        "## cross validation process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehs5jrGAbJSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a683787c-2f0d-4adb-f5ba-9615005990e7"
      },
      "source": [
        "results = []\n",
        "for ii,(epochs,conscious_state) in enumerate(zip([unconscious.copy(),\n",
        "                                                  see_maybe.copy(),\n",
        "                                                  conscious.copy()],\n",
        "                                                 ['unconscious',\n",
        "#                                                  'glimpse',\n",
        "#                                                  'conscious'\n",
        "                                                 ])):\n",
        "    epochs\n",
        "    epochs = epochs.pick_types(eeg=True)\n",
        "\n",
        "    X_,y_               = epochs.get_data(),epochs.events[:,-1]\n",
        "    y_                  = y_ //100 - 2\n",
        "    X,targets           = X_.copy(),y_.copy()\n",
        "    targets             = np.vstack([targets,1-targets]).T\n",
        "\n",
        "    X                   = mne.decoding.Scaler(epochs.info).fit_transform(X)\n",
        "    # because RNN take input's last dimension as the feature while the second the last dimension as time step\n",
        "    X                   = np.swapaxes(X,1,2)\n",
        "    ss                  = []\n",
        "    cv                  = StratifiedShuffleSplit(n_splits=n_splits,test_size = 0.15,random_state=12345)\n",
        "    for fold,(idx_,idx_test) in enumerate(cv.split(X,targets)):\n",
        "\n",
        "        X_train,X_valid,y_train,y_valid = train_test_split(\n",
        "                            X[idx_],targets[idx_],\n",
        "                            test_size           = 0.15,\n",
        "                            random_state        = 12345,\n",
        "                            shuffle             = True,)\n",
        "\n",
        "        model_name  = 'RNN.hdf5'\n",
        "        batch_size  = 10\n",
        "        timesteps   = X.shape[1]\n",
        "        data_dim    = X.shape[2]\n",
        "        n_units     = 1\n",
        "        n_layers    = 1\n",
        "        dropout     = True\n",
        "        # make the model\n",
        "        classifier = build_model(timesteps   = timesteps,\n",
        "                                            data_dim    = data_dim,\n",
        "                                            n_units     = n_units,\n",
        "                                            batch_size  = batch_size,\n",
        "                                            n_layers    = n_layers,\n",
        "                                            drop        = dropout)\n",
        "        print(f'the model has {classifier.count_params()} parameters')\n",
        "        if print_model:\n",
        "            classifier.summary()\n",
        "            print_model = False\n",
        "        # compile the model with optimizer, loss function\n",
        "        classifier.compile(optimizer                = optimizers.Adam(lr = 1e-4),\n",
        "                           loss                     = losses.categorical_crossentropy,\n",
        "                           metrics                  = [k_metrics.categorical_accuracy])\n",
        "        # early stopping\n",
        "        callBackList = make_CallBackList(\n",
        "                           model_name,\n",
        "                           verbose                  = 0,# print out the process\n",
        "                           frequency                = 1,\n",
        "                           **call_back_dict(classifier,'loss'))\n",
        "\n",
        "        # prepare the data\n",
        "        X_train,y_train = prepare_data_batch(X_train,y_train,batch_size = batch_size)\n",
        "        X_valid,y_valid = prepare_data_batch(X_valid,y_valid,batch_size = batch_size)\n",
        "        # put weights on minor class\n",
        "        class_weight    = dict(Counter(y_train[:,0]))\n",
        "        class_weight    = {key:(y_train.shape[0] - value)/value for key,value in class_weight.items()}\n",
        "        sample_weight   = [class_weight[item] for item in y_train[:,0]]\n",
        "        print(class_weight)\n",
        "\n",
        "        # train and validate\n",
        "        np.random.seed(12345)\n",
        "        X_train,y_train = shuffle(X_train,y_train)\n",
        "        classifier.fit(X_train,y_train,\n",
        "                       batch_size               = batch_size,\n",
        "                       epochs                   = n_epochs,\n",
        "                       validation_data          = (X_valid,y_valid),\n",
        "                       callbacks                = callBackList,\n",
        "                       shuffle                  = True,\n",
        "                       sample_weight            = np.array(sample_weight), # this is the key !\n",
        "                       verbose                  = 0)\n",
        "\n",
        "        # test the trained model\n",
        "        classifier.load_weights(model_name)\n",
        "\n",
        "        X_test,y_test = prepare_data_batch(X[idx_test],targets[idx_test],batch_size = batch_size)\n",
        "\n",
        "\n",
        "        preds = classifier.predict(X_test,batch_size=batch_size,verbose = 0)\n",
        "\n",
        "        ss.append(metrics.roc_auc_score(y_test,preds,average = 'micro'))\n",
        "        print(f'{conscious_state},fold {fold+1},{ss[-1]:.4f}\\n')\n",
        "        K.clear_session()\n",
        "    results.append([conscious_state,ss])\n",
        "print([np.mean(item[1]) for item in results])\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the model has 492 parameters\n",
            "Model: \"clf\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "inputs (InputLayer)          [(10, 150, 60)]           0         \n",
            "_________________________________________________________________\n",
            "rnn1 (GRU)                   [(10, 150, 1), (10, 1)]   186       \n",
            "_________________________________________________________________\n",
            "norm1 (BatchNormalization)   (10, 150, 1)              4         \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (10, 150)                 0         \n",
            "_________________________________________________________________\n",
            "outputs (Dense)              (10, 2)                   302       \n",
            "=================================================================\n",
            "Total params: 492\n",
            "Trainable params: 490\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n",
            "{0: 0.917098445595855, 1: 1.0903954802259888}\n",
            "unconscious,fold 1,0.5218\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 1.0903954802259888, 0: 0.917098445595855}\n",
            "unconscious,fold 2,0.6018\n",
            "\n",
            "the model has 492 parameters\n",
            "{0: 0.7619047619047619, 1: 1.3125}\n",
            "unconscious,fold 3,0.4647\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 1.032967032967033, 0: 0.9680851063829787}\n",
            "unconscious,fold 4,0.5782\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 1.1511627906976745, 0: 0.8686868686868687}\n",
            "unconscious,fold 5,0.4306\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 1.032967032967033, 0: 0.9680851063829787}\n",
            "unconscious,fold 6,0.3312\n",
            "\n",
            "the model has 492 parameters\n",
            "{0: 0.8407960199004975, 1: 1.1893491124260356}\n",
            "unconscious,fold 7,0.6141\n",
            "\n",
            "the model has 492 parameters\n",
            "{0: 0.7703349282296651, 1: 1.2981366459627328}\n",
            "unconscious,fold 8,0.5063\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 0.8048780487804879, 0: 1.2424242424242424}\n",
            "unconscious,fold 9,0.5086\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 0.85, 0: 1.1764705882352942}\n",
            "unconscious,fold 10,0.4076\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 1.0786516853932584, 0: 0.9270833333333334}\n",
            "unconscious,fold 11,0.5733\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 1.4503311258278146, 0: 0.6894977168949772}\n",
            "unconscious,fold 12,0.4529\n",
            "\n",
            "the model has 492 parameters\n",
            "{0: 0.93717277486911, 1: 1.0670391061452513}\n",
            "unconscious,fold 13,0.3710\n",
            "\n",
            "the model has 492 parameters\n",
            "{1: 0.9576719576719577, 0: 1.0441988950276244}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66gd4zFAbNSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}